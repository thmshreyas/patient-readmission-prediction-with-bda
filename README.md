# ğŸ¥ Patient Readmission Prediction using Big Data Technologies

This project predicts **patient readmission probability** using **Machine Learning** integrated with **Apache Kafka**, **Apache Spark**, and **Hadoop (HDFS)** for real-time big data processing.
It includes two dashboards:

1. **Data Input Dashboard** â€“ to send patient details to Kafka.
2. **Prediction Dashboard** â€“ to display predictions streamed from Kafka via Spark ML.

---

## ğŸš€ Project Overview

### Architecture Workflow

1. **User Input Dashboard** â†’ Publishes patient details to a Kafka topic (`patient-input`).
2. **Apache Kafka** â†’ Acts as a message broker for streaming patient data.
3. **Apache Spark Structured Streaming** â†’ Reads from Kafka, processes and predicts using a trained ML model.
4. **HDFS (Hadoop Distributed File System)** â†’ Stores both raw and processed data.
5. **Prediction Dashboard** â†’ Displays the predicted readmission status to users.

---

## ğŸ§  Technologies Used

| Component           | Technology     |
| ------------------- | -------------- |
| Programming         | Python 3.10    |
| Frontend            | Streamlit      |
| Machine Learning    | scikit-learn   |
| Streaming           | Apache Kafka   |
| Big Data Processing | Apache Spark   |
| Storage             | Hadoop HDFS    |
| Data Serialization  | JSON / Parquet |

---

## ğŸ—‚ï¸ Project Structure

```
patient-readmission-prediction-with-bda/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ dashboard_input.py           # Streamlit UI for data entry (publishes to Kafka)
â”‚   â”œâ”€â”€ dashboard_predict.py         # Streamlit UI for showing predictions
â”‚   â”œâ”€â”€ kafka_producer.py            # Sends user input to Kafka topic
â”‚   â”œâ”€â”€ spark_kafka_consumer.py      # Spark job to read from Kafka, predict, and store in HDFS
â”‚   â”œâ”€â”€ model.pkl                    # Trained RandomForest model
â”‚   â””â”€â”€ preprocessing.py             # Handles encoding, feature scaling, etc.
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ patient_data.csv             # Example dataset used for model training
â”‚   â”œâ”€â”€ predictions/                 # HDFS target output (can be linked)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ model_training.ipynb         # ML model training notebook
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .env                             # (Optional) Environment variables for paths, Kafka server, etc.
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Install Dependencies

Clone the repo and create a virtual environment:

```bash
git clone https://github.com/<your-username>/patient-readmission-prediction-with-bda.git
cd patient-readmission-prediction-with-bda

python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
```

### 2ï¸âƒ£ Start Hadoop

Make sure Hadoop is running:

```bash
start-dfs.cmd
start-yarn.cmd
```

Access the Hadoop UI at:

```
http://localhost:9870
```

### 3ï¸âƒ£ Start Zookeeper and Kafka

Open new terminals and run:

```bash
# Terminal 1: Start Zookeeper
zookeeper-server-start.bat config\zookeeper.properties

# Terminal 2: Start Kafka broker
kafka-server-start.bat config\server.properties
```

### 4ï¸âƒ£ Create Kafka Topics

```bash
kafka-topics.bat --create --topic patient-input --bootstrap-server localhost:9092
kafka-topics.bat --create --topic patient-predictions --bootstrap-server localhost:9092
```

To verify:

```bash
kafka-topics.bat --list --bootstrap-server localhost:9092
```

### 5ï¸âƒ£ Run Spark Streaming Job

Start the Spark consumer to process Kafka messages and store results in HDFS:

```bash
python app\spark_kafka_consumer.py
```

You should see logs like:

```
âœ… Spark session started successfully
âœ… Model loaded successfully
âœ… Connected to Kafka topic: patient-input
```

### 6ï¸âƒ£ Run Dashboards

#### ğŸ©º Input Dashboard

This dashboard allows users to input patient data and send it to Kafka.

```bash
streamlit run app/dashboard_input.py
```

Access it at: [http://localhost:8501](http://localhost:8501)

#### ğŸ“Š Prediction Dashboard

Displays predicted readmission results (live updates).

```bash
streamlit run app/dashboard_predict.py
```

Access it at: [http://localhost:8502](http://localhost:8502)

---

## ğŸ§© Example Input Format

| Feature            | Example   |
| ------------------ | --------- |
| race               | Caucasian |
| gender             | Male      |
| age                | 60        |
| time_in_hospital   | 10        |
| num_lab_procedures | 35        |
| num_procedures     | 2         |
| num_medications    | 25        |
| number_outpatient  | 0         |
| number_emergency   | 0         |
| number_inpatient   | 1         |
| number_diagnoses   | 5         |

---

## ğŸ§® Model Details

* **Algorithm:** Random Forest Classifier
* **Libraries:** scikit-learn, pandas, numpy
* **Input Features:** 11 clinical and demographic attributes
* **Output:** Probability of readmission (`Yes` / `No`)

---

## ğŸ“ Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Streamlit  â”‚â”€â”€â”€â”€â”€â”€â–¶ â”‚ Apache     â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ Apache     â”‚
â”‚ Dashboard  â”‚        â”‚ Kafka      â”‚       â”‚ Spark      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ (Predictionâ”‚
                                            â”‚ + HDFS Write)
                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â”‚
                                                    â–¼
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚ HDFS   â”‚
                                               â”‚ Output â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§¾ Output

After each prediction, results are stored in:

```
hdfs://localhost:9870/user/hadoop/patient_predictions/
```

Each record includes:

```json
{
  "patient_id": "12345",
  "age": 60,
  "gender": "Male",
  "num_medications": 25,
  "num_procedures": 2,
  "prediction": "Readmitted"
}
```

---

## ğŸ§° Troubleshooting

| Issue                                           | Cause                                    | Fix                                                          |
| ----------------------------------------------- | ---------------------------------------- | ------------------------------------------------------------ |
| `kafka-topics.bat not recognized`               | Kafka not in PATH                        | Add Kafka `bin/windows` to system PATH                       |
| `ValueError: could not convert string to float` | Categorical encoding missing             | Ensure `LabelEncoder`/`OneHotEncoder` used before prediction |
| Spark canâ€™t read Kafka topic                    | Topic name mismatch or Kafka not running | Restart Kafka and re-check topic name                        |
| HDFS folder not visible                         | Spark hasnâ€™t written yet                 | Wait until Spark microbatch writes output (check logs)       |

---

## âœ¨ Future Enhancements

* Deploy using **Docker Compose** for one-click setup.
* Add **model retraining pipeline** using Spark MLlib.
* Include **real-time visualization** using Kafka Streams dashboard.

---

## ğŸ‘¨â€ğŸ’» Contributors

* **Your Name** â€“ Project Lead & Developer
* (Add your teammates if applicable)

---

## ğŸ“ License

This project is licensed under the **MIT License** â€“ feel free to use and modify with credit.

---

**ğŸ¯ End Goal:**
An intelligent, real-time big data system capable of predicting hospital readmissions using integrated AI and Big Data pipelines.
